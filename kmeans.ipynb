{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1RM2zKOkIqxJg3xwTH1J5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelportomoura/ufla-gcc128-inteligencia-artificial/blob/main/kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalho K-means\n",
        "\n",
        "Aluno: Rafael Porto Vieira de Moura  \n",
        "Matrícula: 201820274"
      ],
      "metadata": {
        "id": "QZ03FuOW8epW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background\n"
      ],
      "metadata": {
        "id": "sTKp3g0-8nbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means\n",
        "\n",
        "O algoritmo K-Means é uma técnica de agrupamento de dados que visa dividir um conjunto de dados em k grupos, onde k é um número pré-definido, com base na similaridade dos seus elementos. O algoritmo funciona em etapas, onde inicialmente são escolhidos k centros de gravidade aleatórios, que serão usados como referência para os demais elementos. Em seguida, cada elemento é associado ao centro de gravidade mais próximo, criando assim os primeiros k grupos. Depois, o centro de gravidade de cada um desses grupos é recalculado e o processo é repetido até que a convergência seja alcançada. O resultado final é um conjunto de k grupos, onde cada grupo representa uma clusterização dos dados, com base nas suas características e na distância entre eles.\n",
        "\n",
        "A distância utilizada como métrica é a distância euclidiana, representada pela equação abaixo, onde $p$ e $p'$ são dois objetoros representados por vetores no espaço e n é a quantidade de dimensões.\n",
        "\n",
        "\n",
        "$$ d(p,q) = \\sqrt{\\sum_{i=1}^{n}{(p - q)^2}} $$"
      ],
      "metadata": {
        "id": "lA40lnhD8syT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Set Iris\n",
        "\n",
        "O conjunto de dados Iris é um dos conjuntos mais icônicos e amplamente utilizados em aprendizado de máquina e estatísticas. Ele contém informações sobre três espécies diferentes de plantas de íris: Setosa, Versicolor e Virginica. Para cada uma das 150 amostras de íris, são registradas quatro características: comprimento e largura das sépalas e pétalas. Esse conjunto de dados é frequentemente utilizado para tarefas de classificação e clustering, bem como para ilustrar conceitos fundamentais em análise de dados e visualização. Graças à sua simplicidade e clareza, o conjunto de dados Iris é uma escolha popular para iniciantes em aprendizado de máquina, bem como para pesquisadores que desejam explorar algoritmos e técnicas de análise de dados. O conjunto de dados pode ser acessado no repositório UCI Machine Learning e é uma valiosa ferramenta para estudos e experimentos na área de ciência de dados.\n",
        "\n",
        "[Página do dataset](https://archive.ics.uci.edu/dataset/53/iris)\n"
      ],
      "metadata": {
        "id": "BI0ZwyQA-JPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código\n",
        "\n"
      ],
      "metadata": {
        "id": "vcGeGiTw8aA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cabeçalho"
      ],
      "metadata": {
        "id": "SBJmJZxG-Qdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import  load_iris\n",
        "import numpy as np\n",
        "import math\n",
        "from random import uniform\n",
        "import statistics\n"
      ],
      "metadata": {
        "id": "YuI5tJ2N-iX1"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logger"
      ],
      "metadata": {
        "id": "lBlQ0yyF-N08"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "6b5hgOwr79cF"
      },
      "outputs": [],
      "source": [
        "class Logger:\n",
        "    def __init__(self,log_type: str):\n",
        "        self.log_type = log_type if log_type else 'standard'\n",
        "        self.__error__ = log_type in ['debug','info','standard', 'error']\n",
        "        self.__info__ = log_type in ['debug','info','standard']\n",
        "        self.__debug_logs__ = log_type in ['debug','standard']\n",
        "        self.__log__ = log_type in ['debug','info','standard','log','error']\n",
        "\n",
        "    def debug(self,*args):\n",
        "        if(self.__debug_logs__):\n",
        "            print('🪰',*args)\n",
        "    def info(self,*args):\n",
        "        if(self.__info__):\n",
        "            print('📣',*args)\n",
        "    def error(self,*args):\n",
        "        if(self.__error__):\n",
        "            print(\"❌ ERROR::\",*args)\n",
        "    def log(self,*args):\n",
        "        if(self.__log__):\n",
        "            print(*args)\n",
        "\n",
        "logger = Logger('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means"
      ],
      "metadata": {
        "id": "YAN_EXJv_YP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distância euclidiana e de Minkowski"
      ],
      "metadata": {
        "id": "05G3rJ9F_bep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distancia_euclidiana(p: list,q: list) -> float:\n",
        "    subtraidos = np.subtract(p,q)\n",
        "    elevado = np.power(subtraidos,2)\n",
        "    somatorio = np.sum(elevado)\n",
        "    distancia = math.sqrt(somatorio)\n",
        "    return distancia\n",
        "\n",
        "def distancia_minkowski(p: list, q: list, m: int) -> float:\n",
        "    subtraidos = np.subtract(p,q)\n",
        "    elevado = np.power(subtraidos, m)\n",
        "    somatorio = np.sum(elevado)\n",
        "    distancia = np.power(somatorio, 1/m)\n",
        "    return distancia"
      ],
      "metadata": {
        "id": "_IUgqKfp_bCO"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means"
      ],
      "metadata": {
        "id": "o29gphr5tjnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KMeans:\n",
        "    def __init__(self, numero_de_grupos: int, pontos: list):\n",
        "        if numero_de_grupos <= 1:\n",
        "            raise Exception('Número de grupos deve ser maior do que 1!')\n",
        "        if numero_de_grupos > len(pontos):\n",
        "            raise Exception('Número de grupos é maior que a quantidade de elementos!')\n",
        "        self.pontos = pontos\n",
        "        self.numero_de_grupos = numero_de_grupos\n",
        "\n",
        "    def agrupa(self, k_centros_iniciais: list) -> list:\n",
        "        grupos = self.agrupa_por_centros(k_centros_iniciais)\n",
        "        centro_antigo = k_centros_iniciais.copy()\n",
        "        novos_centros = self.atualiza_os_centros(grupos)\n",
        "        while centro_antigo != novos_centros:\n",
        "            centro_antigo = novos_centros.copy()\n",
        "            grupos = self.agrupa_por_centros(novos_centros)\n",
        "            novos_centros = self.atualiza_os_centros(grupos)\n",
        "            logger.debug(\"novos_centros:\", novos_centros)\n",
        "        return grupos\n",
        "\n",
        "    def agrupa_por_centros(self, centros: list) -> list:\n",
        "        grupos = []\n",
        "        for ponto in self.pontos:\n",
        "            menor_distancia = float('inf')\n",
        "            grupo_menor_distancia = 0\n",
        "            for grupo_centro in range(len(centros)):\n",
        "                distancia = distancia_euclidiana(ponto, centros[grupo_centro])\n",
        "                if distancia < menor_distancia:\n",
        "                    menor_distancia = distancia\n",
        "                    grupo_menor_distancia = grupo_centro\n",
        "\n",
        "            grupos.append(grupo_menor_distancia)\n",
        "        return grupos\n",
        "\n",
        "    def definir_centro(self, pontos: list) -> float:\n",
        "        dimensoes = len(pontos[0])\n",
        "        quantidade_de_pontos = len(pontos)\n",
        "\n",
        "        centro = []\n",
        "        for dimensao in range(dimensoes):\n",
        "            centro.append(statistics.mean([p[dimensao] for p in pontos]))\n",
        "\n",
        "        return centro\n",
        "\n",
        "    def atualiza_os_centros(self, grupos: list) -> list:\n",
        "        pontos_por_grupo = {}\n",
        "\n",
        "        centros = [[] for _  in range(self.numero_de_grupos)]\n",
        "\n",
        "        for i in range(len(grupos)):\n",
        "            grupo = grupos[i]\n",
        "            ponto = self.pontos[i]\n",
        "            if grupo not in pontos_por_grupo:\n",
        "                pontos_por_grupo[grupo] = []\n",
        "\n",
        "            pontos_por_grupo[grupo].append(ponto)\n",
        "\n",
        "        for grupo in pontos_por_grupo:\n",
        "            centros[grupo] = self.definir_centro(pontos_por_grupo[grupo])\n",
        "\n",
        "        return centros"
      ],
      "metadata": {
        "id": "JtrR6FV1tojk"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções de definir centro inicial"
      ],
      "metadata": {
        "id": "8NZXFutUzzAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def centros_iniciais_aleatorios(grupos: int, pontos: list):\n",
        "    dimensoes = len(pontos[0])\n",
        "    min = {}\n",
        "    max = {}\n",
        "    for dimensao in range(dimensoes):\n",
        "        min[dimensao] = float('inf')\n",
        "        max[dimensao] = float('-inf')\n",
        "\n",
        "    for ponto in pontos:\n",
        "        for dimensao in range(dimensoes):\n",
        "            valor = ponto[dimensao]\n",
        "            minimo = min[dimensao]\n",
        "            maximo = max[dimensao]\n",
        "\n",
        "            if valor < minimo:\n",
        "                min[dimensao] = valor\n",
        "\n",
        "            if valor > maximo:\n",
        "                max[dimensao] = valor\n",
        "\n",
        "    centros = []\n",
        "    for _ in range(grupos):\n",
        "        ponto_aleatorio = []\n",
        "        for dimensao in range(dimensoes):\n",
        "            minimo = min[dimensao]\n",
        "            maximo = max[dimensao]\n",
        "            ponto_aleatorio.append(uniform(minimo, maximo))\n",
        "        centros.append(ponto_aleatorio)\n",
        "    return centros\n",
        "\n"
      ],
      "metadata": {
        "id": "RDsUGkunzvZS"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def media_dos_dados_reais() -> list:\n",
        "    setosa = [5.006, 3.418, 1.464, 0.244]\n",
        "    versicolor = [5.936, 2.77, 4.26, 1.326]\n",
        "    virginica = [6.588, 2.974, 5.552, 2.026]\n",
        "    return [setosa, versicolor, virginica]\n",
        ""
      ],
      "metadata": {
        "id": "g5pwBWGL561l"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aleatorio_com_maior_sucesso() -> list:\n",
        "    setosa = [5.005999999999999, 3.428000000000001, 1.4620000000000002, 0.2459999999999999]\n",
        "    versicolor = [5.901612903225807, 2.748387096774194, 4.393548387096775, 1.4338709677419357]\n",
        "    virginica = [6.8500000000000005, 3.073684210526315, 5.742105263157893, 2.0710526315789473]\n",
        "    return [setosa, versicolor, virginica]"
      ],
      "metadata": {
        "id": "kPI_QM1laiND"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chute_humano() -> list:\n",
        "    setosa = [5.,3.5,1.5,0.2]\n",
        "    versicolor = [5.5,2.7,4.3,1.3]\n",
        "    virginica = [6.8,3.,5.5,2.1]\n",
        "    return [setosa, versicolor, virginica]"
      ],
      "metadata": {
        "id": "POtDgt75xPXr"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orquestrador\n"
      ],
      "metadata": {
        "id": "4QNwC2VRA3Em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rodar k-means\n"
      ],
      "metadata": {
        "id": "RjI8mbio_zId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rodar_k_means(grupos: int, pontos: list, k_centros_iniciais: list):\n",
        "    try:\n",
        "        logger.debug(f\"rodar_k_means(\\n\\t{grupos},\\n\\t{pontos},\\n\\t{k_centros_iniciais}\\n)\")\n",
        "        kmeans = KMeans(grupos, pontos)\n",
        "        resultado = kmeans.agrupa(k_centros_iniciais)\n",
        "        return resultado\n",
        "    except Exception as e:\n",
        "        logger.error(e.__str__())\n",
        "\n",
        "def porcentagem_de_acerto(agrupados: list, corretos: list):\n",
        "    acertos = 0\n",
        "    erros = 0\n",
        "    total = len(corretos)\n",
        "    for agrupado, correto in zip(agrupados,corretos):\n",
        "        if agrupado == correto:\n",
        "            acertos += 1\n",
        "        else:\n",
        "            erros += 1\n",
        "\n",
        "    return (acertos/total) * 100"
      ],
      "metadata": {
        "id": "iwXEVNUw_2Gp"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Iris\n"
      ],
      "metadata": {
        "id": "VtQVAMC3-qnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento do dataset"
      ],
      "metadata": {
        "id": "NtpxjQFM_EMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IRIS_PONTOS, IRIS_CLASSES = load_iris(return_X_y=True)"
      ],
      "metadata": {
        "id": "HM1WwUZu-skm"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rodar K-means com Iris"
      ],
      "metadata": {
        "id": "Vv2l1eQ7_OHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMERO_DE_GRUPOS = 3\n",
        "# k_centros_iniciais = centros_iniciais_aleatorios(grupos, pontos)\n",
        "# k_centros_iniciais = aleatorio_com_maior_sucesso()\n",
        "k_centros_iniciais = media_dos_dados_reais()\n",
        "# k_centros_iniciais = chute_humano()\n",
        "resultado = rodar_k_means(NUMERO_DE_GRUPOS,IRIS_PONTOS.tolist(), k_centros_iniciais)\n",
        "acertos = porcentagem_de_acerto(resultado, IRIS_CLASSES)\n",
        "logger.info(IRIS_CLASSES.tolist())\n",
        "logger.info(resultado)\n",
        "logger.log(f\"Acertos: {acertos:.2f}%\")"
      ],
      "metadata": {
        "id": "hraXBdF1_SSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5da9a3-682b-4693-8257-70a75c5f79b4"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acertos: 88.67%\n"
          ]
        }
      ]
    }
  ]
}